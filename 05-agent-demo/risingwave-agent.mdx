---
title: "Use Agents to analyze data ingested into RisingWave"
---

## Overview



In this tutorial, you will learn how to implement a custom Anthropic Agent, integrate it with RisingWave MCP, to do simple stream processing with RisingWave.

If you want a reference to the full project you can clone [this](https://github.com/risingwavelabs/awesome-stream-processing/) repository.

## Prerequisites

* Install and run RisingWave. For detailed instructions on how to quickly get started, see the [Quick start](/get-started/quickstart/) guide.
* Ensure you have an [Anthropic](https://console.anthropic.com/settings/keys) API key.
* Ensure that the [PostgreSQL](https://www.postgresql.org/docs/current/app-psql.html) interactive terminal, `psql`, is installed in your environment. For detailed instructions, see [Download PostgreSQL](https://www.postgresql.org/download/).
* Ensure that you have cloned the [RisingWave MCP](https://github.com/risingwavelabs/risingwave-mcp.git).

## Step 1: Create the file 'client.py'

Here are the basic imports necessary for the file

```python
import os
import asyncio
import json
import re
from fastmcp import Client
from anthropic import Anthropic
from tabulate import tabulate
import sys
from dotenv import load_dotenv
```

The try_print_table function is there to help the agent understand how to parse tables and other data formats, so that it can output the data in a clean and readable way for the user. It verifies that the user request is asking to print a table and from there will call the function and parse through it properly. 

```python
load_dotenv()
def try_print_table(result):
    try:
        data = json.loads(result)
        
        if isinstance(data, list) and all(isinstance(row, dict) for row in data):
            print(tabulate(data, headers="keys", tablefmt="github"))
            return True
        if isinstance(data, list) and all(isinstance(row, list) for row in data):
            print(tabulate(data, tablefmt="github"))
            return True
    except Exception as e:
        if isinstance(result, list) and len(result) == 1 and hasattr(result[0], "text"):
            return True
    return False
    
def extract_table_names(query): 
    return re.findall(r"(?:from|in|of|table|view|into)\\s+([a-zA-Z0-9_]+)", query, re.IGNORECASE)
```

This is the beginning of the risingWaveMCPAgent class, it instantiates the Agent with the proper environment variables. It should be notes that they are set up to work with Rising Wave on local host if you are running Rising Wave elsewhere, please edit the environment variables so that the client can properly connect to your Rising Wave instance. From there we list a few basic functions to ensure the agent has proper access to the tools. It will cache this tool list to ensure the agent has quick access to these tools. It also has the functions aenter and aexit to ensure that the connection to the MCP Server is opened only once and maintained from there on. 

```python
class risingWaveMCPAgent:
    def __init__(self, server_script_path: str):
        self.client = Client(server_script_path)
        env = {
            "RISINGWAVE_HOST": os.getenv("RISINGWAVE_HOST", "0.0.0.0"),
            "RISINGWAVE_USER": os.getenv("RISINGWAVE_USER", "root"),
            "RISINGWAVE_PASSWORD": os.getenv("RISINGWAVE_PASSWORD", "root"),
            "RISINGWAVE_PORT": os.getenv("RISINGWAVE_PORT", "4566"),
            "RISINGWAVE_DATABASE": os.getenv("RISINGWAVE_DATABASE", "dev"),
            "RISINGWAVE_SSLMODE": os.getenv("RISINGWAVE_SSLMODE", "disable")
        }
        self.client.transport.env = env
        self.anthropic = Anthropic()
        self.conversation = []
        self._tools_cache = None


    async def list_tools(self):
        if self._tools_cache is None:
            tools = await self.client.list_tools()
            self._tools_cache = [{
                "name": tool.name,
                "description": tool.description,
                "input_schema": tool.inputSchema
            } for tool in tools]
        return self._tools_cache

    async def __aenter__(self):
        await self.client.__aenter__()
        return self

    async def __aexit__(self, exc_type, exc, tb):
        await self.client.__aexit__(exc_type, exc, tb)
```

Continuing with the risingWaveMCPAgent class, this section declares a few more function for the agent. These functions allow it to actually invoke the use of a tool and fetch schema context from the a table if needed. The handle tool use actually calls the call_tool function whenever and logs it's use so the user understands the agnets process. It will also save the log of which tools were called on which object for the agent to maintain context of the current session. Handle LLM response will filer the LLM response so that it does not output encoded text and ensure that the agent outputs clean and readable text.

```python
async def call_tool(self, tool_name, args):
        return await self.client.call_tool(tool_name, args)

    async def fetch_schema_context(self, table_names):
        async def fetch(table):
            try:
                schema = await self.call_tool("describe_table", {"table_name": table})
                return f"Schema for table '{table}':\n{schema}"
            except Exception as e:
                return f"Could not fetch schema for table '{table}': {e}"
        return await asyncio.gather(*(fetch(table) for table in set(table_names)))

   

    async def handle_tool_use(self, content, final_text):
        tool_name = content.name
        tool_args = content.input
        result = await self.call_tool(tool_name, tool_args)
        final_text.append(f"[Calling tool {tool_name} with args {tool_args}]")
        if not try_print_table(result):
            final_text.append(result)
        self.conversation.append({"role": "user", "content": result})

        response = self.anthropic.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=1000,
            messages=self.conversation,
        )
        self.handle_llm_response(response, final_text)

    def handle_llm_response(self, response, final_text):
        if response.content and response.content[0].type == 'text':
            final_text.append(response.content[0].text)
            self.conversation.append({"role": "assistant", "content": response.content[0].text})
```

These final agent functions allow the agent to process the user query and establish the chat loop for the agent. Process query extracts key words from the users query and has the agent interpret them in order to decide whether or not tool use is required. If a tool is not required it will call the anthropic model to respond to the user using it's context from previous queries in the session. If there is tool use invoked, it will take a look at the tool list cached earlier. From there it will call the necessary tool to respond to the user and log it's actions to maintain context. The function will continue to loop this process to handle the case of multiple tool use in one query. If no tools were used in the last query the agent will stop the loop and return the final message to the user. The chat_loop function sets up this chat loop for the user. 

```python
async def process_query(self, query: str) -> str:
        self.conversation.append({"role": "user", "content": query})

        table_names = extract_table_names(query)
        schema_contexts = await self.fetch_schema_context(table_names) if table_names else []

        messages = self.conversation.copy()
        for schema in schema_contexts:
            messages.append({"role": "user", "content": schema})

        tools = await self.list_tools()

        final_text = []
        while True:
            response = self.anthropic.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=4096,
                messages=messages,
                tools=tools
            )

            tool_used = False
            for content in response.content:
                if content.type == 'text':
                    final_text.append(content.text)
                    self.conversation.append({"role": "assistant", "content": content.text})
                elif content.type == 'tool_use':
                    tool_used = True
                    await self.handle_tool_use(content, final_text)
                    messages = self.conversation.copy()
            if not tool_used:
                break

        return "\n".join(final_text)

    async def chat_loop(self):
        print("Rising Wave MCP Client Started!")
        print("Type your queries or 'quit' to exit.")
        while True:
            try:
                query = input("\nQuery: ").strip()
                if query.lower() == 'quit':
                    break
                response = await self.process_query(query)
                print("\n" + response)
            except Exception as e:
                print(f"\nError: {str(e)}")
```

This main function allows the user to start the program

```python
    async def main():
    if len(sys.argv) < 2:
        print("Usage: python client.py <path_to_server_script>")
        sys.exit(1)
    
    server_script_path = sys.argv[1]
    async with risingWaveMCPAgent(server_script_path) as client:
        await client.chat_loop()
        
if __name__ == "__main__":
    asyncio.run(main())
```

## Step 2: Now that you have the script prepared, you must configure your .env file. Create one now and enter your Anthropic API key where needed
```python
ANTHROPIC_API_KEY = <YOUR-API-KEY-HERE>
RISINGWAVE_HOST = 0.0.0.0
RISINGWAVE_USER = root
RISINGWAVE_PASSWORD = root
RISINGWAVE_PORT = 4566
RISINGWAVE_DATABASE = dev
RISINGWAVE_SSLMODE = disable
RISINGWAVE_TIMEOUT = 30
```


Follow the [tutorial](https://docs.risingwave.com/ingestion/advanced/generate-test-data) to create a load generator or use the following script:

```psql
CREATE TABLE users (
  id int,
  risk int,
  cost int,
  time timestamp
)
WITH (
  connector = 'datagen',

  fields.id.length = '1',
  fields.id.kind = 'sequence',
  fields.id.start = '1000',

  fields.risk.length = '1',
  fields.risk.kind = 'random',
  fields.risk.min = '0',
  fields.risk.max = '10',
  fields.risk.seed = '5',

  fields.cost.length = '1',
  fields.cost.kind = 'random',
  fields.cost.min = '1',
  fields.cost.max = '10000',
  fields.cost.seed = '8',

  fields.time.kind = 'random',
  fields.time.max_past = '5h',
  fields.time.max_past_mode = 'relative',

  datagen.rows.per.second = '10'
)
FORMAT PLAIN ENCODE JSON;
```

To connect to the Agent and start the server as a subprocess use:

```shell
python client.py risingwave-mcp/src/main.py
```

Use the following basic commands to test out the agent's tools:

1. Give me the database version
```bash
I'll help you get the RisingWave database version information using the `get_database_version` function.
[Calling tool get_database_version with args {}]
The database is running PostgreSQL 13.14.0 with RisingWave version 2.2.0 (Homebrew build).
```

2. Show me the users table structure
```bash
Columns:
1. id (integer)
2. risk (integer)
3. cost (integer)
4. time (timestamp without time zone)
5. _row_id (serial) - hidden, primary key
6. _rw_timestamp (timestamp with time zone) - hidden

Additional Information:
- Primary Key: _row_id
- Distribution Key: _row_id
- Table Name: users
```

3. Track the highest risk scores
```bash
I'll help you create a materialized view to track the highest risk scores from the users table. I'll create a view that orders by risk score in descending order.
[Calling tool create_materialized_view with args {'name': 'high_risk_users', 'sql_statement': 'SELECT id, risk, cost, time \nFROM users \nWHERE risk >= 7 \nORDER BY risk DESC'}]
Great! The materialized view 'high_risk_users' has been created. Let me show you the results from this view to see the users with the highest risk scores.
```

4. Sort that mv by highest spending and display
```bash
I'll query the materialized view 'high_risk_users' and sort it by cost in descending order (highest spending) using the run_select_query function.
[Calling tool run_select_query with args {'query': 'SELECT * FROM high_risk_users ORDER BY cost DESC;'}]
Here's an analysis of the high-risk users sorted by spending:

Top 5 highest spending high-risk users:
1. ID: 1398 - Risk: 8, Cost: $9,999
2. ID: 1021 - Risk: 10, Cost: $9,967
3. ID: 1277 - Risk: 8, Cost: $9,949
4. ID: 1642 - Risk: 8, Cost: $9,913
5. ID: 2048 - Risk: 10, Cost: $9,855

Key observations:
- There are 451 users classified as high-risk
- Spending ranges from $11 (lowest) to $9,999 (highest)
- Some users have maximum risk score (10) but varying spending levels
- The view includes users with risk scores 7 and above
```


Feel free to experiment with more prompts and try out with your own data! Similarly, you can use any of the [demos](https://docs.risingwave.com/demos/overview) and test the agent with that data.

When you are done you can have the agent drop the users table or just use 'quit' to stop the program.
